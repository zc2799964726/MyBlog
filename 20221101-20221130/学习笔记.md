本月的学习笔记总结了10月、11月两个月的问题和经验

## 工作上

### 10月(8号国庆回来)

大部分时间在测试影像精度
关于如何查找影像RTK的影像测量功能精度不对的原因：

1. 首先用表格总结当天影像测量任务单点测量的精度，寻找误差较大的影像组；
2. 排除选点错误和刺点错误的情况，随后使用pix4空三解算查看pix4d空三的结果与原始测量的角度、坐标差值、VRTK代码空三与原始测量值、VRTK代码空三与pix4d空三结果比较；
3. 分析是什么因素导致其误差较大的原因，反馈给老师；
4. 利用修改后的算法继续测试；

目前最好的精度测量方式：
**走动一段距离后再测量**
在一共40组测量数据中，单点测量的平面和3D误差小于5cm的比例达到97.5%，仅有一组超过5cm小于10cm。

### 11月

学习了rosbag的解析办法，并尝试解析了影像RTK数据，ORBSLAM3跑通影像RTK数据。
暂时目标：接入实时影像数据跑orbslam

跑的结果
![图片](./assets/点云.png "点云图")

### 完成Smart3D CC 大势智慧-建图大师 CoPre2的安装和数据处理

## 学习上

### C++基本语法学习

首先是学习C++的类
输出了udp Demo

然后是C++的设计模式

1. 创建型模式

- 单例模式
- 简单工厂
- 工厂模式
- 抽象工厂
- 建造者模式
- 原型模式
Demo还在写

2. 结构型模式

3. 行为型模式

### 视觉SLAM十四讲

已经看到第9讲，习题正在补充中
补充

2022.11.20还剩最后一讲13讲：设计SLAM系统

SLAM习题等待补充

#### 实践前的准备

重看一遍slambook2，发现每一章下都有一个整体的CMakelists，发觉只要在其中添加需要的库并链接即可
事实上我是从第七章才开始这么做的

**CMake的学习**
关于CMAKE目前只学习了一些简单的编译库和内置变量，相关资料有CMake practice和CMake cookbook

> <https://www.bookstack.cn/read/CMake-Cookbook/content-preface-preface-chinese.md>

1. 关于slambook2的克隆
由于这本书在克隆的时候包含第三方子模块，这时候想要完整克隆第三方库的话，需要在克隆时加上 --recursive

>某一个项目仓库的一些子模块是通过链接的方式链接到主项目目录上的。而这些子模块的仓库是单独建立在另外的目录下（更多是因为版权问题，使用别人的模块时，并没有直接把源码和自己的项目代码一起上传到自己的仓库，而是通过链接的形式链接到三方

```git
git clone --recursive  https://github.com/gaoxiang12/slambook2.git
```

当然也会遇到一些网速问题导致其他某些子模块克隆失败

可以采用下面这个命令更新所有子模块，单独更新某一具体的子模块我还没找到，以后更新吧。

```git
git submodule update --init --recursive
```

参考：
> <https://blog.csdn.net/toopoo/article/details/104225592>

我到最后还有一个3rdparty/Pangolin/external/pybind11没有克隆完成，不过这个不影响，在配置orbslam3的时候已经克隆好Pangolin0.6了

2. 完成所有第三方库的编译和安装

其实slambook里面坑也蛮多的例如CMakelists的问题

当然本节主要讨论如何把需要的第三方库安装到Ubuntu18.04.6的/usr/local等目录下(也可以不安装，但是安装这样做的好处就是不需要修改每个代码的#include "xxx/xxx.h")

**我的安装过程唯一用slambook2内部的的3rdParty/g2o，其他的都未用slambook2内部克隆下来的库**
本来我的想法是与slambook2保持一致，结果他的好多库编译都出错，所以记录一下

**步骤1：ceres库安装**
若使用slambook2内部的ceres目录下的ceres编译则会报 ' variable or field ‘it’ declared void'
原因我的Eigen3.3.90与之版本不对应，需要用Eigen3.3.7

服了Eigen卸载有点让人难受，所以直接克隆最新版ceres
编译和安装过程都很正常

**步骤2：DBoW3库安装**
也是直接克隆最新版的，没有使用slambook2的
原因：我当时发现slambook2里面有，因为没有用--recursive克隆

**步骤3：g2o库安装**
正常编译安装即可

**步骤4：Sophus库安装**
使用最新的git clone
先安装fmt，再安装Sophus

#### 第二章实践

暂时先放置，相对简单

#### 第三章实践

3.2 实践：Eigen
学会使用 Eigen的相关变量及其函数

> 参考网址：<http://eigen.tuxfamily.org/dox-devel/modules.html>

3.6 实践：Eigen 几何模块

> Eigen 几何模块参考：<http://eigen.tuxfamily.org/dox/group__TutorialGeometry.html>

| 矩阵      | Eigen类型 | 具体使用例子    |  备注 |
| ----------- | ----------- | --------- | ------ |
| 3D旋转矩阵(3x3)      | Matrix3d |  `Matrix3d r = Matrix3d::Identity()` 归一化|
| 旋转向量(3x1)   | AngleAxisd   | 有很多构造函数：`AngleAxisd r(M_PI/4,Vector3d(0,0,1));` |
| 欧拉角(3x1) |  Vector3d [旋转矩阵.eulerAngles(2,1,0)] | ZXY顺序| roll pitch yaw|
| 欧氏变换矩阵(4x4) |  Isometry3d | `Isometry T = Isometry::Identity();//虽然称之为3d，实际上是4*4的矩阵` |
| 四元数(4x1) | `Quaterniond q = Quaterniond(r_v)` `q = Quaterniond(r_m)` | 直接把AngleAxis赋给四元数，反之也可以| `q.coeffs()` (x,y,z,w),w为实部 `q*v`:数学上是qvq^-1,等于`q*v*q.inverse()` |
| 仿射变换(4x4) | Affine3d | | |
| 射影变换(4x4) | Projective3d | | |

关于欧式变换矩阵的旋转和平移：
`T.rotate(r);T.pretranslate(Vector3d(1,3,4))`

3.7 轨迹可视化
利用plotTrajectory程序稍作修改，可以将ORBSLAM3跑园区的数据存储下来的关键帧轨迹和相机轨迹显示出来

![图片](./assets/KeyFrameTrajectory.png "图1")
         KeyFrameTrajectory.png
![图片](./assets/CameraTrajectory.png "图2")
CameraTrajectory.png
可以看出来相机的轨迹图比关键帧的轨迹更加稠密（废话）

存储格式：time,tx,ty,tz,qx,qy,qz,qw

严格的说，存储的是相机坐标系原点OR在世界坐标系中的坐标OW

OW = TWR * OR = tWR

从TWR中可以直接看到相机在何处，所以可视化程序中，为了直观，轨迹文件存储了TWR而不是TRW

使用的可视化库为Pangolin支持OpenGL

> OpenGL 参考：<https://www.bookstack.cn/books/OpenGL>

#### 第四章实践 - Sophus

**目标**
SLAM中位姿是未知的，解决：什么样的相机位姿最符合当前的观测数据

1. 学会SO3 SE3对应李代数so3 se3的表示方式
2. 理解BCH近似的意义
3. 学会在李代数上的扰动模型
4. 使用Sophus对李代数进行运算

旋转矩阵自带约束：正交且行列式=1 为了更简单的优化它，使用利群李代数间的转换关系，把位姿估计变成无约束的优化问题

CMakelists 里需要链接fmt库，具体使用办法：

```CMake
find_package(fmt REQUIRED)
set(FMT_LIBRARIES fmt::fmt)

target_link_libraries(trajectoryError ${Pangolin_LIBRARIES} ${FMT_LIBRARIES})
```

> <https://blog.csdn.net/CSSDCC/article/details/121854773>

![图片](./assets/TrajectoryError.png "图3")


**BCH**
两个李代数指数映射的乘积的形式由BCH公式给出（BCH的线性近似）
ln(exp(A)exp(B)) = A+B+1/2[A,B]+1/12[A,[A,B]]-1/12[B,[A,B]]+···
其中 [] 为李括号
优化过程中导数是必要的信息。
对旋转矩阵R对应李代数为$\phi$.给他左乘一个微小旋转$\Delta$R,对应的李代数为
$\Delta$$\phi$,
那么在李群上，结果为$\Delta$R·R,再用BCH转换到李代数上（方便程序计算），近似为
$\boldsymbol{J}^{-1}$($\phi$)$\Delta$$\phi$+$\phi$
可以写出：
exp($\Delta$$\phi$^) exp($\phi$^) = exp(($\phi$+ $\boldsymbol{J}^{-1}$($\phi$)$\Delta$$\phi$+$\phi$)^)
反之：
在李代数上加法，转换成李群上的带 左乘雅可比 或者 右乘雅可比的乘法(此处略)

然后就可以对李代数求导了

1. 用李代数表示姿态，根据李代数加法对李代数求导
2. 对李群左乘或右乘微小扰动，然后对该扰动求导，称为左扰动或右扰动模型

主要看左扰动模型


> 参考网址：https://blog.csdn.net/qq_37394634/article/details/125831119

#### 第五章实践 - 相机与图像

**目标**

1. 针孔相机模型
2. 内参
3. 标定方法

暂时先把结果图放上来，有关CMakelists的修改如下
参考第四章的fmt
读取并显示图像
![图片](./assets/imageBasics.png "图4")

利用内参去畸变
![图片](./assets/undistort.png "图5")

双目重建
![图片](./assets/stereoVision.png "图6")

双目重建点云
![图片](./assets/stereoVisionCloud.png "图7")

rgbd重建点云
![图片](./assets/rgbd.png "图8")

针孔相机模型：

![图片](./assets/%E5%86%85%E5%8F%82.png)

单目成像过程：

1. 世界坐标系下一点P，$P_w$
2. 由于相机的运动，其运动由R，t或变换矩阵T $\in$ SE3描述
P的相机坐标为[X,Y,Z] = $\bar{P}_c$ = R$P_w$+t
3. 归一化坐标$P_c$ = $[X/Z,Y/Z,1]$
4. 根据畸变参数计算畸变后的坐标$P_c$
5. P的归一化坐标经过内参后，得到像素坐标$P_{uv} = KP_c$

#### 第六章实践 - 非线性优化

**本章的主要目标就是3个**

1. 理解最小二乘的含义和处理方式
2. 理解高斯牛顿法、列文伯格-马夸特方法(LB-MQ)
3. Ceres和g2o库

首先就把g2o的使用办法列出来：

1. 定义顶点和边
2. 构建图
3. 选择优化算法
4. 调用g2o进行优化，返回结果

我看代码是：

1. 定义图优化类型
2. 选择优化算法
3. 添加顶点和边
4. 调用g2o

书上的例子：

0. 定义g2o

```c++
// 构建图优化，先设定g2o
  typedef g2o::BlockSolver<g2o::BlockSolverTraits<3, 1>> BlockSolverType;  // 每个误差项优化变量维度为3，误差值维度为1
  typedef g2o::LinearSolverDense<BlockSolverType::PoseMatrixType> LinearSolverType; // 线性求解器类型
```

0. 梯度下降方法，求增量

```c++
// 梯度下降方法，可以从GN, LM列文伯格-马夸尔特, DogLeg 中选
  auto solver = new g2o::OptimizationAlgorithmGaussNewton(g2o::make_unique<BlockSolverType>(g2o::make_unique<LinearSolverType>()));
  g2o::SparseOptimizer optimizer;     // 图模型
  optimizer.setAlgorithm(solver);   // 设置求解器
  optimizer.setVerbose(true);       // 打开调试输出
```

1. 1.1定义顶点

```c++
// 往图中增加顶点
  CurveFittingVertex *v = new CurveFittingVertex();
  v->setEstimate(Eigen::Vector3d(ae, be, ce));
  v->setId(0);
  optimizer.addVertex(v);
```

1. 1.2定义边

```c++
// 往图中增加边
  for (int i = 0; i < N; i++) {
    CurveFittingEdge *edge = new CurveFittingEdge(x_data[i]);
    edge->setId(i);
    edge->setVertex(0, v);                // 设置连接的顶点
    edge->setMeasurement(y_data[i]);      // 观测数值
    edge->setInformation(Eigen::Matrix<double, 1, 1>::Identity() * 1 / (w_sigma * w_sigma)); // 信息矩阵：协方差矩阵之逆
    optimizer.addEdge(edge);
  }
```


```c++
// 执行优化
  cout << "start optimization" << endl;
  chrono::steady_clock::time_point t1 = chrono::steady_clock::now();
  optimizer.initializeOptimization();
  optimizer.optimize(10);
  chrono::steady_clock::time_point t2 = chrono::steady_clock::now();
  chrono::duration<double> time_used = chrono::duration_cast<chrono::duration<double>>(t2 - t1);
  cout << "solve time cost = " << time_used.count() << " seconds. " << endl;
```

```c++
// 输出优化值
  Eigen::Vector3d abc_estimate = v->estimate();
  cout << "estimated model: " << abc_estimate.transpose() << endl;
```

参考第四章的fmt

实践的结果就是和书上一样

> ceres 参考：https:ceres-solver.org/tutorial.html

> g2o 参考：doxygen doxy.config生成的

#### 第七章实践 - 视觉里程计1

**目标**

1. 图像特征、提取、匹配
2. 对极几何恢复三维运动
3. PNP问题利用一直三维结构与图像对应关系求 相机的三维运动
4. ICP顶阿芸匹配关机恢复相机三维运动
5. 三角化获得 二位图像上对应点的三维结构

再参考第四章链接fmt库即可
每一个可执行文件都需要链接

7.2.1 ORB特征提取与匹配实践

代码相对简单

![图片](./assets/orbcv.png)

7.2.2 手写orb特征提取和匹配

这段代码相对复杂

分为4步
- 读取图像
- 计算特征点
- 匹配
- 画图

计算特征时先使用Fast提取角点，再用自己写的 ComputeORB(img, kpts,desc)
输出的参数是desc
计算特征点角度->计算描述子

匹配时使用BfMatch


![图片](./assets/orbself.png)

7.4 对极约束求解相机运动

匹配特征点->2d2d->求出E或F->分解E或F求R t(opencv输出1组)

//-- 把匹配点转换为vector<Point2f>的形式

//-- 计算基础矩阵
Mat fundamental_matrix;
fundamental_matrix = findFundamentalMat(points1, points2, CV_FM_8POINT);
cout << "fundamental_matrix is " << endl << fundamental_matrix << endl;

//-- 计算本质矩阵
Point2d principal_point(325.1, 249.7);  //相机光心, TUM dataset标定值
double focal_length = 521;      //相机焦距, TUM dataset标定值
Mat essential_matrix;
essential_matrix = findEssentialMat(points1, points2, focal_length, principal_point);

//-- 计算单应矩阵
//-- 但是本例中场景不是平面，单应矩阵意义不大
Mat homography_matrix;
homography_matrix = findHomography(points1, points2, RANSAC, 3);

recoverPose(essential_matrix, points1, points2, R, t, focal_length, principal_point);


![图片](./assets/2d2d.png)

7.6 三角测量

对极几何估计相机运动，再利用相机运动估计特征点的空间位置，使用三角化(Triangulation)

![图片](./assets/Triangulation.png)


7.8 PnP P3P


```bash
./build/pose_estimation_3d2d 1.png 2.png 1_depth.png 2_depth.png 
-- Max dist : 95.000000 
-- Min dist : 4.000000 
一共找到了79组匹配点
3d-2d pairs: 76
solve pnp in opencv cost time: 0.00584756 seconds.
R=
[0.9978662025826269, -0.05167241613316376, 0.03991244360207524;
 0.0505958915956335, 0.998339762771668, 0.02752769192381471;
 -0.04126860182960625, -0.025449547736074, 0.998823919929363]
t=
[-0.1272259656955879;
 -0.007507297652615337;
 0.06138584177157709]
calling bundle adjustment by gauss newton
iteration 0 cost=45538.1857253
iteration 1 cost=413.221881688
iteration 2 cost=301.36705717
iteration 3 cost=301.365779441
pose by g-n: 
    0.99786620258  -0.0516724160901   0.0399124437155   -0.127225965886
   0.050595891549    0.998339762774     0.02752769194 -0.00750729768072
 -0.0412686019426  -0.0254495477483    0.998823919924   0.0613858418151
                0                 0                 0                 1
solve pnp by gauss newton cost time: 0.000203345 seconds.
calling bundle adjustment by g2o
iteration= 0     chi2= 413.221882        time= 6.9732e-05        cumTime= 6.9732e-05     edges= 76       schur= 0
iteration= 1     chi2= 301.367057        time= 1.7204e-05        cumTime= 8.6936e-05     edges= 76       schur= 0
iteration= 2     chi2= 301.365779        time= 1.5441e-05        cumTime= 0.000102377    edges= 76       schur= 0
iteration= 3     chi2= 301.365779        time= 2.055e-05         cumTime= 0.000122927    edges= 76       schur= 0
iteration= 4     chi2= 301.365779        time= 2.1088e-05        cumTime= 0.000144015    edges= 76       schur= 0
iteration= 5     chi2= 301.365779        time= 4.0525e-05        cumTime= 0.00018454     edges= 76       schur= 0
iteration= 6     chi2= 301.365779        time= 2.4022e-05        cumTime= 0.000208562    edges= 76       schur= 0
iteration= 7     chi2= 301.365779        time= 1.781e-05         cumTime= 0.000226372    edges= 76       schur= 0
iteration= 8     chi2= 301.365779        time= 2.1264e-05        cumTime= 0.000247636    edges= 76       schur= 0
iteration= 9     chi2= 301.365779        time= 1.7481e-05        cumTime= 0.000265117    edges= 76       schur= 0
optimization costs time: 0.002280437 seconds.
pose estimated by g2o =
   0.997866202583  -0.0516724161336   0.0399124436024   -0.127225965696
   0.050595891596    0.998339762772   0.0275276919261 -0.00750729765631
   -0.04126860183  -0.0254495477384    0.998823919929   0.0613858417711
                0                 0                 0                 1
solve pnp by g2o cost time: 0.002643775 seconds.
```


7.10 ICP(略)

#### 第八章实践 - 视觉里程计2

**目标**

1. 光流法跟踪原理
2. 直接法如何估计相机位姿
3. 直接法与特征点法的对比总结表
4. 实现多层直接法的实现

```CMake
find_package(OpenCV 4 REQUIRED)
#find_package(OpenCV 3.0.0 REQUIRED)# 2个opencv的使用办法
```

再参考第四章链接fmt库即可

编译如果报error: 'CV_GRAY2BGR' was not declared in this scope的错误
只需要在cpp文件中加入#include <opencv2/imgproc/types_c.h>这句话即可完美编译

**如何在项目中区分使用opencv3和opencv4而不会产生冲突**

> <https://blog.csdn.net/qq_43525260/article/details/104152392>



8.3 LK光流

![图片](./assets/LK.png)

8.5 直接法

![图片](./assets/direct.png)

#### 第九章实践 - 后端1

fmt


9.3 Ceres BA

![图片](./assets/initial.png)

![图片](./assets/final.png)

9.4 G2O BA
![图片](./assets/initialg2o.png)


![图片](./assets/finalg2o.png)


#### 第十章实践 - 后端2

fmt
使用g2o_viewer
![图片](./assets/posGraph_sphere.png)

优化后

![图片](./assets/posGraphOptimize.png)

使用SE3
![图片](./assets/posGraphG2OSE3.png)

使用李代数
![图片](./assets/posGraphG2Olie.png)


#### 第十一章实践 - 回环检测

改成opencv4

11.3.2 创建字典



11.4.2 相似度的计算


#### 第十二章实践 - 建图

**编译前的事情**

1. 安装PCL点云库

sudo apt-get install libpcl-dev pcl-tools

2. 安装octmap

> <https://blog.csdn.net/zhiwei121/article/details/90605096>
书上说18.04版本之后，可用按照书上的命令行，我的是18.04.6，没有尝试
sudo apt-get install liboctomap-dev octovis
**编译程序**

##### 12.3 单目稠密重建

首先需要去下载数据，然后运行数据集

下载结束解压后我放在ch12/dense_mono/ 下

运行程序：
zc@zc-virtual:~/slambook2/ch12/build$ ./dense_mono/dense_mapping ../dense_mono/test_data/

![图片](./assets/monoDensemapping.png)

![图片](./assets/monoDensemapping1.png)

##### 12.4 RGB-D 稠密重建

###### 12.4.1 点云地图

运行程序：
../build/dense_RGBD/pointcloud_mapping

运行结果：
正在将图像转换为点云...
转换图像中: 1
转换图像中: 2
转换图像中: 3
转换图像中: 4
转换图像中: 5
点云共有1309800个点.
滤波之后，点云共有31876个点.

pcl-viewer查看：
pcl_viewer -i map.pcd

![图片](./assets/RGBDpointcloud.png "RGBDpointcloud")

###### 12.4.2 点云重建网格

重建的算法是 Moving Least Square 和 Greedy Projection
//TODO 参考文献
> 参考文献: [130] [131]

运行程序：
../build/dense_RGBD/surfel_mapping map.pcd

运行结果：
point cloud loaded, points: 31876
computing normals ...
computing mesh ...
display mesh ...

![图片](./assets/surfelmapping.png "surfelmapping")

###### 12.4.3 八叉树地图

不同分辨率的条件下
深度为1：

![图片](./assets/octomap.png)

深度为5：
![图片](./assets/octomap1.png)

深度为16：
![图片](./assets/octomap2.png)

##### 实时三维重建

TSDF地图和Fusion系列

TSDF 是 Truncated Signed Distance Function 的缩写
截断符合距离函数

TSDF地图也是网格式地图，存储于显存中，对深度图依赖更深

#### 第十三章实践 - 设计SLAM系统

关于配置环境
> <https://blog.csdn.net/jiachang98/article/details/121700288>

//TODO
完成6个设计模式的Demo

单例模式

### 存在的问题

rostopic发布时存在卡顿的情况，暂时还未解决
